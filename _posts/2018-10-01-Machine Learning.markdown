---
layout: post
title:  "Machine Learning"
date:   2018-10-01 00:01:57 +0800
categories: machine-learning
---
## 學習算法
* 監督學習
	* 樣本有相應的正確答案(訓練集)
	* 據樣本做預測
	* 回歸：推測連續值輸出
		* 舉例：
			* 預測房價
	* 分類；推出一組離散值結果
		* 舉例：
			* 預測乳腺癌
	* 分析：
		* 重要是能預測未來，便於做決策
		* 作者用了預測未來三個月能賣幾件相同的產品，做為回歸的舉例。判斷不同帳號是否曾被盜，作為分類的舉例
		* 學分類
			* 好處不用自己分類。可用在居家收納，同類的衣服放一起，像襪子、衣服、褲子自成一類
			* 反面的例子，亂中有序，依個人解讀不同，也可能有人無法解讀，判斷為亂。像房間亂，以個人來說那是有序，因你大致知道東西放哪，但對第一次來到你房間的人來說，那是一個亂。
			* 使用條件：異類資料
			* 相似資訊：類似數學的集合
			* 亂中有序與分類相異的地方，亂中有序不需再做分類，分類則需要。相同的地方，最初的資料都很亂，最後的資料皆有序
		* 學回歸
			* 好處預測明日氣溫是高或低
			* 反面的例子，相對於分類
			* 使用條件：同類資料
			* 相似資訊：類似匯率
			* 分類與回歸相異的地方，一個是確定最後會分類，一個是最後會有一個預測值。相同的地方，都為監督學習
* 無監督學習
	* 一堆未分組的數據，自動分組
	* 聚類算法
	* 舉例：
		* 谷歌新聞
		* 是否有特定基因
		* 什麼樣的機器易協同工作
		* 朋友分組
		* 雞尾酒算法，音頻分類
		* 細分市場
		* 糖尿病
* 算法
	* 定義：即工具，如何恰當使用這些工具
	* 單變量線性回歸算法
		* 模型  
		![Linear Regression with One Variable_Model variable](/assets/Linear Regression with One Variable_Model variable.png)
		* 代價函數
			* 代價函數/損失函數越小，就代表了模型對訓練數據擬合的越好。即最優化經驗風險

## 參考
* [吳恩達的機器學習教程中文筆記](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)
* [知乎吳恩達的機器學習與深度學習](https://zhuanlan.zhihu.com/p/35940466)
